#!/usr/bin/env node

import { Command } from 'commander';
import app from './app';
import { version } from '../package.json'
import { loadModelMapping, getMappedModelName } from './config/modelMapping';
// Êâ©Â±ïÂÖ®Â±ÄÂØπË±°Á±ªÂûã
declare global {
  var verboseLogging: boolean;
}

const program = new Command();

program
  .name('mock-openai-api')
  .description('Mock OpenAI Compatible Provider API server')
  .version(version)
  .option('-p, --port <number>', 'Server port', '3000')
  .option('-H, --host <address>', 'Server host address', '0.0.0.0')
  .option('-v, --verbose', 'Enable request logging to console', false)
  .option('-c, --config <path>', 'Path to model mapping config file', './model-mapping.json')
  .parse();

const options = program.opts();

const PORT = parseInt(options.port) || 3000;
const HOST = options.host || '0.0.0.0';

// ËÆæÁΩÆÂÖ®Â±ÄÂèòÈáèÊéßÂà∂Êó•ÂøóËæìÂá∫
global.verboseLogging = options.verbose;

// Load model mapping configuration
loadModelMapping(options.config);

app.listen(PORT, HOST, () => {
  console.log(`üöÄ Mock OpenAI API server started successfully!`);
  console.log(`üìç Server address: http://${HOST}:${PORT}`);
  console.log(`‚öôÔ∏è  Configuration:`);
  console.log(`   ‚Ä¢ Port: ${PORT}`);
  console.log(`   ‚Ä¢ Host: ${HOST}`);
  console.log(`   ‚Ä¢ Verbose logging: ${options.verbose ? 'ENABLED' : 'DISABLED'}`);
  console.log(`   ‚Ä¢ Config file: ${options.config}`);
  console.log(`   ‚Ä¢ Version: ${version}`);
  console.log(`üìñ API Documentation:`);
  console.log(`   ‚Ä¢ GET  /health - Health check`);
  console.log(`   ‚Ä¢ GET  /v1/models - Get OpenAI model list`);
  console.log(`   ‚Ä¢ POST /v1/chat/completions - OpenAI chat completions`);
  console.log(`   ‚Ä¢ POST /v1/images/generations - OpenAI image generation`);
  console.log(`   ‚Ä¢ GET  /anthropic/v1/models - Get Anthropic model list`);
  console.log(`   ‚Ä¢ POST /anthropic/v1/messages - Anthropic message API`);
  console.log(`   ‚Ä¢ GET  /v1beta/models - Get Gemini model list`);
  console.log(`   ‚Ä¢ POST /v1beta/models/{model}:generateContent - Gemini content generation`);
  console.log(`   ‚Ä¢ POST /v1beta/models/{model}:streamGenerateContent - Gemini streaming generation`);
  console.log(`\n‚ú® Available models:`);
  console.log(`   OpenAI Compatible:`);
  console.log(`   - ${getMappedModelName('mock-gpt-thinking')}: Model supporting thought process`);
  console.log(`   - ${getMappedModelName('gpt-4-mock')}: Model supporting function calls`);
  console.log(`   - ${getMappedModelName('mock-gpt-markdown')}: Model outputting standard Markdown`);
  console.log(`   - ${getMappedModelName('gpt-4o-image')}: Model specifically for image generation`);
  console.log(`   Anthropic Compatible:`);
  console.log(`   - ${getMappedModelName('mock-claude-markdown')}: Claude markdown sample model`);
  console.log(`   Gemini Compatible:`);
  console.log(`   - ${getMappedModelName('gemini-1.5-pro')}: Advanced multimodal AI model`);
  console.log(`   - ${getMappedModelName('gemini-1.5-flash')}: Fast and efficient model`);
  console.log(`   - ${getMappedModelName('gemini-pro')}: Versatile model for various tasks`);
  console.log(`   - ${getMappedModelName('gemini-pro-vision')}: Multimodal model for text and images`);
  console.log(`\nüîó Usage example:`);
  console.log(`   curl -X POST http://localhost:${PORT}/v1/chat/completions \\`);
  console.log(`     -H "Content-Type: application/json" \\`);
  console.log(`     -d '{`);
  console.log(`       "model": "${getMappedModelName('gpt-4-mock')}",`);
  console.log(`       "messages": [{"role": "user", "content": "Hello"}]`);
  console.log(`     }'`);
  console.log(`\nüí° CLI Options:`);
  console.log(`   ‚Ä¢ Use --help to see all available options`);
  console.log(`   ‚Ä¢ Use -v or --verbose to enable request logging`);
  console.log(`   ‚Ä¢ Use -p <port> to specify custom port`);
  console.log(`   ‚Ä¢ Use -H <host> to specify custom host address`);
  console.log(`   ‚Ä¢ Use -c <path> to specify custom config file`);
}); 
